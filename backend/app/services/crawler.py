"""
ë©”ì¸ í¬ë¡¤ë§ ì„œë¹„ìŠ¤
ê³µê°œì •ë³´ ìˆ˜ì§‘ ë° í†µí•© ê´€ë¦¬
"""

import os
from typing import Dict, List, Optional
from .dart_service import DartService
from .news_service import NewsService
from .web_scraper import WebScraper

class CrawlerService:
    """í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ë©”ì¸ í´ëž˜ìŠ¤"""
    
    def __init__(self):
        self.dart_service = DartService()
        self.news_service = NewsService()
        self.web_scraper = WebScraper()
    
    def crawl_public_data(self, homepage: str, company_name: str = None) -> Dict:
        """
        ê³µê°œì •ë³´ ìˆ˜ì§‘ ë° í†µí•©
        
        Args:
            homepage: ê¸°ì—… í™ˆíŽ˜ì´ì§€ URL
            company_name: ê¸°ì—…ëª… (ì„ íƒì‚¬í•­)
            
        Returns:
            Dict: ìˆ˜ì§‘ëœ ê³µê°œì •ë³´
        """
        try:
            # ê¸°ì—…ëª… ì¶”ì¶œ
            if not company_name:
                company_name = self._extract_company_name(homepage)
            
            print(f"ðŸ” {company_name} ê³µê°œì •ë³´ ìˆ˜ì§‘ ì‹œìž‘...")
            
            # ë³‘ë ¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
            results = {
                'company': company_name,
                'homepage': homepage,
                'news': [],
                'dart': [],
                'social': [],
                'website': {},
                'crawl_date': self._get_current_date(),
                'status': 'success'
            }
            
            # ë‰´ìŠ¤ ìˆ˜ì§‘
            try:
                print("ðŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
                results['news'] = self.news_service.fetch_news(company_name, homepage)
                print(f"âœ… ë‰´ìŠ¤ {len(results['news'])}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                results['news'] = []
            
            # DART ê³µì‹œ ìˆ˜ì§‘
            try:
                print("ðŸ“‹ DART ê³µì‹œ ìˆ˜ì§‘ ì¤‘...")
                dart_key = os.getenv('DART_API_KEY')
                results['dart'] = self.dart_service.fetch_filings(company_name, dart_key)
                print(f"âœ… DART ê³µì‹œ {len(results['dart'])}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ DART ê³µì‹œ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                results['dart'] = []
            
            # ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘
            try:
                print("ðŸŒ ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
                results['website'] = self.web_scraper.scrape_website(homepage)
                print("âœ… ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                results['website'] = {}
            
            # ì†Œì…œ ë¯¸ë””ì–´ ìˆ˜ì§‘ (ë”ë¯¸ ë°ì´í„°)
            try:
                print("ðŸ“± ì†Œì…œ ë¯¸ë””ì–´ ìˆ˜ì§‘ ì¤‘...")
                results['social'] = self._get_sample_social(company_name)
                print(f"âœ… ì†Œì…œ ë¯¸ë””ì–´ {len(results['social'])}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ì†Œì…œ ë¯¸ë””ì–´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                results['social'] = []
            
            print(f"ðŸŽ‰ {company_name} ê³µê°œì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ!")
            return results
            
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                'company': company_name or 'Unknown',
                'homepage': homepage,
                'news': [],
                'dart': [],
                'social': [],
                'website': {},
                'crawl_date': self._get_current_date(),
                'status': 'error',
                'error': str(e)
            }
    
    def _extract_company_name(self, homepage: str) -> str:
        """í™ˆíŽ˜ì´ì§€ URLì—ì„œ ê¸°ì—…ëª… ì¶”ì¶œ"""
        import re
        from urllib.parse import urlparse
        
        try:
            parsed = urlparse(homepage)
            domain = parsed.netloc or parsed.path
            
            # www ì œê±°
            domain = domain.replace('www.', '')
            
            # ë„ë©”ì¸ì—ì„œ ê¸°ì—…ëª… ì¶”ì¶œ
            parts = domain.split('.')
            if len(parts) >= 2:
                company_name = parts[0]
                # íŠ¹ìˆ˜ë¬¸ìž ì œê±° ë° ëŒ€ë¬¸ìž ë³€í™˜
                company_name = re.sub(r'[^a-zA-Z0-9ê°€-íž£]', '', company_name)
                return company_name.capitalize()
            
            return domain.capitalize()
            
        except Exception:
            return 'Unknown Company'
    
    def _get_sample_social(self, company_name: str) -> List[Dict]:
        """ìƒ˜í”Œ ì†Œì…œ ë¯¸ë””ì–´ ë°ì´í„° ìƒì„±"""
        return [
            {
                'title': f'{company_name} ì†Œì…œ ì–¸ê¸‰ 1',
                'url': f'https://social.example.com/{company_name}/1',
                'snippet': 'ê³ ê° ë§Œì¡±/ë¶ˆë§Œ, í‰íŒ ì´ìŠˆ ìš”ì•½.',
                'source': 'social',
                'date': '2024-01-12'
            },
            {
                'title': f'{company_name} ì†Œì…œ ì–¸ê¸‰ 2',
                'url': f'https://social.example.com/{company_name}/2',
                'snippet': 'ë¸Œëžœë“œ ì¸ì§€ë„ ë° ê³ ê° í”¼ë“œë°±.',
                'source': 'social',
                'date': '2024-01-10'
            }
        ]
    
    def _get_current_date(self) -> str:
        """í˜„ìž¬ ë‚ ì§œ ë°˜í™˜"""
        from datetime import datetime
        return datetime.now().strftime('%Y-%m-%d %H:%M:%S')
