"""
ë‰´ìŠ¤ í¬ë¡¤ë§ ì„œë¹„ìŠ¤
Google News RSS ë° ê¸°íƒ€ ë‰´ìŠ¤ ì†ŒìŠ¤ ìˆ˜ì§‘
"""

import re
import time
from typing import Dict, List, Optional
from urllib.parse import quote_plus
import requests
from bs4 import BeautifulSoup

class NewsService:
    """ë‰´ìŠ¤ í¬ë¡¤ë§ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.google_news_base = "https://news.google.com/rss/search"
        self.timeout = 10
        self.max_retries = 3
    
    def fetch_news(self, company_name: str, homepage: str = None, limit: int = 10) -> List[Dict]:
        """
        ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
        
        Args:
            company_name: ê¸°ì—…ëª…
            homepage: í™ˆí˜ì´ì§€ URL (ì„ íƒì‚¬í•­)
            limit: ìˆ˜ì§‘í•  ë‰´ìŠ¤ ìˆ˜ ì œí•œ
            
        Returns:
            List[Dict]: ë‰´ìŠ¤ ë°ì´í„° ëª©ë¡
        """
        try:
            print(f"ğŸ“° {company_name} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
            
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            queries = self._build_search_queries(company_name, homepage)
            
            collected_news = []
            seen_urls = set()
            
            # ê° ì¿¼ë¦¬ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘
            for query in queries:
                if len(collected_news) >= limit:
                    break
                
                try:
                    news_items = self._fetch_google_news(query, limit - len(collected_news))
                    
                    for item in news_items:
                        if item['url'] not in seen_urls:
                            seen_urls.add(item['url'])
                            collected_news.append(item)
                            
                        if len(collected_news) >= limit:
                            break
                    
                    # ìš”ì²­ ê°„ ì§€ì—°
                    time.sleep(1)
                    
                except Exception as e:
                    print(f"âš ï¸ ì¿¼ë¦¬ '{query}' ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                    continue
            
            print(f"âœ… ë‰´ìŠ¤ {len(collected_news)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
            return collected_news[:limit]
            
        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return self._get_sample_news(company_name, limit)
    
    def _build_search_queries(self, company_name: str, homepage: str = None) -> List[str]:
        """ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        queries = []
        
        # ê¸°ì—…ëª… ì¶”ê°€
        if company_name:
            queries.append(company_name)
            if len(company_name) > 3:
                queries.append(f'"{company_name}"')
        
        # í™ˆí˜ì´ì§€ì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ
        if homepage:
            domain_match = re.search(r'https?://([^/]+)', homepage)
            if domain_match:
                domain = domain_match.group(1)
                # www ì œê±°
                domain = domain.replace('www.', '')
                # ë„ë©”ì¸ì—ì„œ í† í° ì¶”ì¶œ
                parts = domain.split('.')
                if parts and parts[0].lower() not in ['www', 'm']:
                    queries.append(parts[0])
        
        # ì¤‘ë³µ ì œê±°
        unique_queries = []
        seen = set()
        for query in queries:
            if query not in seen:
                seen.add(query)
                unique_queries.append(query)
        
        return unique_queries
    
    def _fetch_google_news(self, query: str, limit: int) -> List[Dict]:
        """Google News RSSì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        try:
            # Google News RSS URL ìƒì„±
            url = f"{self.google_news_base}?q={quote_plus(query)}&hl=ko&gl=KR&ceid=KR:ko"
            
            response = requests.get(url, timeout=self.timeout)
            if response.status_code != 200:
                print(f"âš ï¸ Google News RSS ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                return []
            
            # XML íŒŒì‹±
            soup = BeautifulSoup(response.content, 'xml')
            news_items = []
            
            for item in soup.find_all('item')[:limit]:
                title_elem = item.find('title')
                link_elem = item.find('link')
                desc_elem = item.find('description')
                pub_date_elem = item.find('pubDate')
                
                title = title_elem.text.strip() if title_elem else ""
                link = link_elem.text.strip() if link_elem else ""
                description = desc_elem.text.strip() if desc_elem else ""
                pub_date = pub_date_elem.text.strip() if pub_date_elem else ""
                
                if title and link:
                    news_item = {
                        'title': title,
                        'url': link,
                        'snippet': description,
                        'source': 'news',
                        'date': pub_date,
                        'query': query
                    }
                    news_items.append(news_item)
            
            return news_items
            
        except Exception as e:
            print(f"âŒ Google News ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _get_sample_news(self, company_name: str, limit: int) -> List[Dict]:
        """ìƒ˜í”Œ ë‰´ìŠ¤ ë°ì´í„° ìƒì„±"""
        return [
            {
                'title': f'{company_name} ê´€ë ¨ ë³´ë„ 1',
                'url': f'https://news.example.com/{company_name}/1',
                'snippet': f'{company_name}ì˜ ìµœê·¼ ë™í–¥ê³¼ ë¦¬ìŠ¤í¬ ìš”ì¸ ë¶„ì„ ìš”ì•½.',
                'source': 'news',
                'date': '2024-01-15',
                'query': company_name
            },
            {
                'title': f'{company_name} ê´€ë ¨ ë³´ë„ 2',
                'url': f'https://news.example.com/{company_name}/2',
                'snippet': f'{company_name}ì˜ ê²½ì˜ í˜„í™©ê³¼ í–¥í›„ ì „ë§.',
                'source': 'news',
                'date': '2024-01-10',
                'query': company_name
            },
            {
                'title': f'{company_name} ê´€ë ¨ ë³´ë„ 3',
                'url': f'https://news.example.com/{company_name}/3',
                'snippet': f'{company_name}ì˜ ì‹œì¥ ë™í–¥ê³¼ ê²½ìŸì‚¬ ë¶„ì„.',
                'source': 'news',
                'date': '2024-01-05',
                'query': company_name
            }
        ][:limit]
